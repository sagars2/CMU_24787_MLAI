{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note for question1 !\n",
    "- Please **do not** change the default variable names in this problem, as we will use them in different parts.\n",
    "- The default variables are initially set to \"None\".\n",
    "- You only need to modify code in the \"TODO\" part. We added a lot of \"assertions\" to check your code. **Do not** modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P1. Load data and plot\n",
    "### TODO\n",
    "- Load train and test data, and split them into inputs(trainX, testX) and labels(trainY, testY)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to load q1_train.csv and q1_test.csv\n",
    "# Each data point has 200 features(X), followed by 1 label(Y)\n",
    "train = pd.read_csv('q1_train.csv')\n",
    "test = pd.read_csv('q1_test.csv')\n",
    "#### TODO ####\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "trainX = train[:,1:201]\n",
    "trainY = train[:,201]\n",
    "testX = test[:,1:201]\n",
    "testY = test[:,201]\n",
    "##############\n",
    "\n",
    "assert(len(trainX.shape) == 2)\n",
    "assert(len(trainY.shape) == 1)\n",
    "assert(trainX.shape[1] == 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2. Write your Gaussian NB solver\n",
    "### TODO\n",
    "- Finish the myNBSolver() function. \n",
    "    - Compute P(y == 0) and P(y == 1), saved in \"py0\" and \"py1\"\n",
    "    - Compute mean/variance of trainX for both y = 0 and y = 1, saved in \"mean0\", \"var0\", \"mean1\" and \"var1\"\n",
    "        - Each of them should have shape (M), where M is number of features.\n",
    "    - Compute P(xi | y == 0) and P(xi | y == 1), compare and save **binary** prediction in \"train_pred\" and \"test_pred\"\n",
    "    - Compute train accuracy and test accuracy, saved in \"train_acc\" and \"test_acc\".\n",
    "    - Return train accuracy and test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myNBSolver(trainX, trainY, testX, testY):\n",
    "    \n",
    "    N_train = trainX.shape[0]\n",
    "    N_test = testX.shape[0]\n",
    "    M = trainX.shape[1]\n",
    "    \n",
    "    #### TODO ####\n",
    "    # Compute P(y == 0) and P(y == 1)\n",
    "    p_y0 = len((np.where(trainY== 0)[0]))\n",
    "    p_y1 = len(np.where(trainY== 1)[0])\n",
    "    \n",
    "    py0 = p_y0/(p_y0+p_y1)\n",
    "    py1 = p_y1/(p_y0+p_y1)\n",
    "    \n",
    "    print(py0)\n",
    "    print(py1)\n",
    "    ##############\n",
    "    print(\"Total probablity is %.2f. Should be equal to 1.\" %(py0 + py1))\n",
    "\n",
    "    #### TODO ####\n",
    "    # Compute mean/var for each label\n",
    "    \n",
    "    mean0 = np.mean(trainX[np.where(trainY==0)],axis=0) \n",
    "    mean1 = np.mean(trainX[np.where(trainY==1)],axis=0)\n",
    "    var0 = np.var(trainX[np.where(trainY==0)],axis=0)\n",
    "    var1 = np.var(trainX[np.where(trainY==1)],axis=0) \n",
    "    \n",
    "    ##############\n",
    "    assert(mean0.shape[0] == M)\n",
    "    \n",
    "    #### TODO ####\n",
    "    # Compute P(xi|y == 0) and P(xi|y == 1), compare and make prediction\n",
    "    train_pred = np.empty((N_train))\n",
    "    test_pred = np.empty((N_test))\n",
    "    for i in range(len(trainX)):\n",
    "        pxy0 = (1/np.sqrt(2*np.pi*var0))*np.exp(-((trainX[i]-mean0)**2)/(2*var0))\n",
    "        a = np.prod(pxy0)\n",
    "        pyx0 = a*py0\n",
    "        pxy1 = (1/np.sqrt(2*np.pi*var1))*np.exp(-((trainX[i]-mean1)**2)/(2*var1))\n",
    "        b = np.prod(pxy1)\n",
    "        pyx1 = b*py1\n",
    "        if pyx0>pyx1:\n",
    "            train_pred[i] = 0\n",
    "        else:\n",
    "            train_pred[i] = 1\n",
    "        if (i%1000==0):\n",
    "            print(i)\n",
    "    for j in range(len(testX)):\n",
    "        pxy0 = (1/np.sqrt(2*np.pi*var0))*np.exp(-((testX[j]-mean0)**2)/(2*var0))\n",
    "        a = np.prod(pxy0)\n",
    "        pyx0 = a*py0\n",
    "        pxy1 = (1/np.sqrt(2*np.pi*var1))*np.exp(-((testX[j]-mean1)**2)/(2*var1))\n",
    "        b = np.prod(pxy1)\n",
    "        pyx1 = b*py1\n",
    "        if pyx0>pyx1:\n",
    "            test_pred[j] = 0\n",
    "        else:\n",
    "            test_pred[j] = 1\n",
    "        if (j%1000==0):\n",
    "            print(j)\n",
    "            \n",
    "\n",
    "#     pxy0 = (np.prod(pxy0))\n",
    "#     pxy1 = (np.prod(pxy1))\n",
    "        \n",
    "                                                 \n",
    "    # This part may spend 5 - 10 minutes or even more if you use for loop, so feel free to \n",
    "    # print something (like step number) to check the progress\n",
    "    \n",
    "        \n",
    "    ##############\n",
    "    assert(train_pred[0] == 0 or train_pred[0] == 1)\n",
    "    assert(test_pred[0] == 0 or test_pred[0] == 1)\n",
    "    \n",
    "    #### TODO ####\n",
    "    # Compute train accuracy and test accuracy\n",
    "    g = np.count_nonzero(train_pred-trainY)\n",
    "    train_acc = 1-(g/len(train_pred))\n",
    "    m = np.count_nonzero(test_pred-testY)\n",
    "    test_acc = 1-(m/len(test_pred))\n",
    "    ##############\n",
    "    \n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9004179104477612\n",
      "0.09958208955223881\n",
      "Total probablity is 1.00. Should be equal to 1.\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "Train accuracy is 92.22\n",
      "Test accuracy is 92.05\n"
     ]
    }
   ],
   "source": [
    "# driver to test your NB solver\n",
    "train_acc, test_acc = myNBSolver(trainX, trainY, testX, testY)\n",
    "print(\"Train accuracy is %.2f\" %(train_acc * 100))\n",
    "print(\"Test accuracy is %.2f\" %(test_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P3. Test your result using sklearn\n",
    "### TODO\n",
    "- Finish the skNBSolver() function. \n",
    "     - fit model, make prediction and return accuracy for train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skNBSolver(trainX, trainY, testX, testY):\n",
    "    \n",
    "    #### TODO ####\n",
    "    # fit model\n",
    "    # make prediction\n",
    "    gnb = GaussianNB()\n",
    "    trainpred = gnb.fit(trainX, trainY).predict(trainX)\n",
    "    testpred = gnb.fit(testX,testY).predict(testX)\n",
    "    # compute accuracy\n",
    "    \n",
    "    s = np.count_nonzero(trainpred-trainY)\n",
    "    l = np.count_nonzero(testpred-testY)\n",
    "    sk_train_acc = 1-(s/len(trainpred))\n",
    "    sk_test_acc = 1-(l/len(testpred))\n",
    "    \n",
    "    ##############\n",
    "    return sk_train_acc, sk_test_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 92.22\n",
      "Test accuracy is 92.17\n"
     ]
    }
   ],
   "source": [
    "# driver to test skNBSolver\n",
    "sk_train_acc, sk_test_acc = skNBSolver(trainX, trainY, testX, testY)\n",
    "print(\"Train accuracy is %.2f\" %(sk_train_acc * 100))\n",
    "print(\"Test accuracy is %.2f\" %(sk_test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
